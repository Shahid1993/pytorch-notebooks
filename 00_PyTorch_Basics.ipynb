{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "a = np.array(1)\n",
    "b = torch.tensor(1)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a), type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(4)\n",
    "b = torch.tensor(2)\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3367, 2.1288, 2.2345],\n",
      "        [2.2303, 0.8771, 1.8137],\n",
      "        [4.2082, 1.3620, 2.4617]])\n",
      "tensor([[-1.6633, -1.8712, -1.7655],\n",
      "        [-1.7697, -3.1229, -2.1863],\n",
      "        [ 0.2082, -2.6380, -1.5383]])\n",
      "tensor([[ 0.6734,  0.2576,  0.4689],\n",
      "        [ 0.4607, -2.2457, -0.3727],\n",
      "        [ 4.4164, -1.2760,  0.9233]])\n",
      "tensor([[ 0.1683,  0.0644,  0.1172],\n",
      "        [ 0.1152, -0.5614, -0.0932],\n",
      "        [ 1.1041, -0.3190,  0.2308]])\n"
     ]
    }
   ],
   "source": [
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3, 3)\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f96a00c24b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345],\n",
       "        [ 0.2303, -1.1229, -0.1863],\n",
       "        [ 2.2082, -0.6380,  0.4617]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(3, 3)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f96a00c24b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288,  0.2345],\n",
      "        [ 0.2303, -1.1229, -0.1863],\n",
      "        [ 2.2082, -0.6380,  0.4617]])\n",
      "tensor([[ 0.2674,  0.5349,  0.8094],\n",
      "        [ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(3, 3)\n",
    "b = torch.randn(3, 3)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6040,  0.6637,  1.0438],\n",
      "        [ 1.3406, -2.8127, -1.1753],\n",
      "        [ 3.1662,  0.6841,  1.2788]]) \n",
      "\n",
      "tensor([[ 0.0693, -0.4061, -0.5749],\n",
      "        [-0.8800,  0.5669,  0.8026],\n",
      "        [ 1.2502, -1.9601, -0.3555]]) \n",
      "\n",
      "tensor([[ 0.4576,  0.2724,  0.3367],\n",
      "        [-1.3636,  1.7743,  1.1446],\n",
      "        [ 0.3243,  2.8696,  2.7954]]) \n",
      "\n",
      "tensor([[ 1.2594,  0.2408,  0.2897],\n",
      "        [ 0.2075,  0.6645,  0.1884],\n",
      "        [ 2.3051, -0.4826,  0.5649]])\n",
      "tensor([[ 0.3367,  0.2303,  2.2082],\n",
      "        [ 0.1288, -1.1229, -0.6380],\n",
      "        [ 0.2345, -0.1863,  0.4617]])\n"
     ]
    }
   ],
   "source": [
    "# matrix addition\n",
    "print(torch.add(a,b), '\\n')\n",
    "\n",
    "# matrix subtraction\n",
    "print(torch.sub(a,b), '\\n')\n",
    "\n",
    "# matrix multiplication (similar to dot product in numpy)\n",
    "print(torch.mm(a, b), '\\n')\n",
    "\n",
    "# matrix division\n",
    "print(torch.div(a, b))\n",
    "\n",
    "# matrix transpose\n",
    "print(torch.t(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2], [3,4]])\n",
    "b = torch.tensor([[5,6], [7,8]])\n",
    "\n",
    "print(a, '\\n')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]]) \n",
      "\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# concatenating vertically\n",
    "print(torch.cat((a, b)), '\\n')\n",
    "\n",
    "# concatenating horizontally\n",
    "print(torch.cat((a,b), dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f96a00c24b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303],\n",
      "        [-1.1229, -0.1863,  2.2082, -0.6380]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(2, 4)\n",
    "\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380]])\n"
     ]
    }
   ],
   "source": [
    "# reshaping tensor\n",
    "b = a.reshape(1,8)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "print(a)\n",
    "\n",
    "# converting the numpy array to tensor\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common PyTorch Modules\n",
    "===\n",
    "\n",
    "## Autograd Module\n",
    "- **PyTorch uses a technique called automatic differentiation.** It records all the operations that we are performing and replays it backward to compute gradients. This technique helps us to save time on each epoch as we are calculating the gradients on the forward pass itself.\n",
    "- Specifying `requires_grad` as `True` will make sure that the gradients are stored for this particular tensor whenever we perform some operation on it.\n",
    "- We perform the following operations on a:  \n",
    "b = a + 5  \n",
    "c = mean(b) = Σ(a+5) / 4  \n",
    "Now, the derivative of c w.r.t. a will be ¼ and hence the gradient matrix will be 0.25. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Initializing a tensor\n",
    "a = torch.ones(2,2,requires_grad=True)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.]], grad_fn=<AddBackward0>) tensor(6., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# performing operations on tensor\n",
    "b = a+5\n",
    "c = b.mean()\n",
    "\n",
    "print(b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "# back propagating\n",
    "c.backward()\n",
    "\n",
    "# computing gradients\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optim Module\n",
    "\n",
    "The Optim module in PyTorch has pre-written codes for most of the optimizers that are used while building a neural network.\n",
    "\n",
    "Most of the commonly used optimizers are supported in PyTorch and hence we do not have to write them from scratch. Some of them are:\n",
    "- SGD\n",
    "- Adam\n",
    "- Adadelta\n",
    "- Adagrad\n",
    "- AdamW\n",
    "- SparseAdam\n",
    "- Adamax\n",
    "- ASGD (Averaged Stochastic Gradient Descent)\n",
    "- RMSprop\n",
    "- Rprop (resilient backpropagation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the optim module\n",
    "from torch import optim\n",
    "\n",
    "# adam\n",
    "## adam = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# sgd\n",
    "## SGD = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Module\n",
    "\n",
    "The autograd module in PyTorch helps us define computation graphs as we proceed in the model. But, just using the autograd module can be low-level when we are dealing with a complex neural network.\n",
    "\n",
    "In those cases, we can make use of the nn module. **This defines a set of functions, similar to the layers of a neural network, which takes the input from the previous state and produces an output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Neural Network from Scratch in PyTorch\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]]) \n",
      "\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "#Input tensor\n",
    "X = torch.Tensor([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "\n",
    "#Output\n",
    "y = torch.Tensor([[1],[1],[0]])\n",
    "\n",
    "print(X, '\\n')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define the sigmoid function which will act as the activation function and the derivative of the sigmoid function which will help us in the backpropagation step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid function\n",
    "def derivatives_sigmoid(x):\n",
    "  return x * (1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, initialize the parameters for our model including the number of epochs, learning rate, weights, biases, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable initialization\n",
    "epoch = 7000  # setting training iterations\n",
    "lr = 0.01  # setting learning rate\n",
    "inputlayer_neurons = X.shape[1]  # No of features in dataset\n",
    "hiddenlayer_neurons = 3\n",
    "output_neurons = 1\n",
    "\n",
    "#weight and bias initialization\n",
    "wh = torch.randn(inputlayer_neurons, hiddenlayer_neurons).type(torch.FloatTensor)\n",
    "bh = torch.randn(1, hiddenlayer_neurons).type(torch.FloatTensor)\n",
    "wout = torch.randn(hiddenlayer_neurons, output_neurons)\n",
    "bout = torch.randn(1, output_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a neural network. I am taking a simple model here just to make things clear. There is a single hidden layer and an input and an output layer in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "  # Forward Propagation\n",
    "  hidden_layer_input1 = torch.mm(X, wh)\n",
    "  hidden_layer_input = hidden_layer_input1 + bh\n",
    "  hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "\n",
    "  output_layer_input1 = torch.mm(hidden_layer_activations, wout)\n",
    "  output_layer_input = output_layer_input1 + bout\n",
    "  output = sigmoid(output_layer_input)\n",
    "\n",
    "  # Backpropagation\n",
    "  E = y - output\n",
    "  slope_output_layer = derivatives_sigmoid(output)\n",
    "  slope_hidden_layer = derivatives_sigmoid(hidden_layer_activations)\n",
    "  \n",
    "  d_output = E * slope_output_layer\n",
    "\n",
    "  error_at_hidden_layer = torch.mm(d_output, wout.t())\n",
    "  d_hidden_layer = error_at_hidden_layer * slope_hidden_layer\n",
    "\n",
    "  wout += torch.mm(hidden_layer_activations.t(), d_output) * lr\n",
    "  bout += d_output.sum() * lr\n",
    "  wh += torch.mm(X.t(), d_hidden_layer) * lr\n",
    "  bh += d_output.sum() * lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual :\n",
      " tensor([[1.],\n",
      "        [1.],\n",
      "        [0.]]) \n",
      "\n",
      "predicted :\n",
      " tensor([[0.9157],\n",
      "        [0.8788],\n",
      "        [0.1715]])\n"
     ]
    }
   ],
   "source": [
    "print('actual :\\n', y, '\\n')\n",
    "print('predicted :\\n', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving an Image Classification Problem using PyTorch\n",
    "\n",
    "Our task is to identify the type of apparel by looking at a variety of apparel images. It’s a classic [image classification](http://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/?utm_source=blog&utm_medium=introduction-to-pytorch-from-scratch) problem using computer vision. This dataset, taken from the [DataHack Platform](https://datahack.analyticsvidhya.com/?utm_source=blog&utm_medium=introduction-to-pytorch-from-scratch), can be downloaded [here](https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/?utm_source=blog&utm_medium=introduction-to-pytorch-from-scratch).\n",
    "\n",
    "\n",
    "Problem Statement\n",
    "---\n",
    "\n",
    "We have total 70,000 images (28 x 28), out of which 60,000 are part of train images with the label of the type of apparel (total classes: 10) and rest 10,000 images are unlabelled (known as test images).The task is to identify the type of apparel for all test images. Given below is the code description for each of the apparel class/label.\n",
    " \n",
    "Label\tDescription\n",
    "--------\n",
    "0\tT-shirt/top  \n",
    "1\tTrouser  \n",
    "2\tPullover  \n",
    "3\tDress  \n",
    "4\tCoat  \n",
    "5\tSandal  \n",
    "6\tShirt  \n",
    "7\tSneaker  \n",
    "8\tBag  \n",
    "9\tAnkle boot  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data from zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile(\"/content/drive/My Drive/ML/data/Identify the Apparels - AnalyticsVidhya/test_ScVgIM0.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\"/content/drive/My Drive/ML/data/Identify the Apparels - AnalyticsVidhya/test_ScVgIM0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile(\"/content/drive/My Drive/ML/data/Identify the Apparels - AnalyticsVidhya/train_LbELtWX.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\"/content/drive/My Drive/ML/data/Identify the Apparels - AnalyticsVidhya/train_LbELtWX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random number generator\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the .csv file that we downloaded from the competition page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1      9\n",
       "1   2      0\n",
       "2   3      0\n",
       "3   4      3\n",
       "4   5      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "train = pd.read_csv(\"../Datasets/Identify the Apparels - AnalyticsVidhya/train_LbELtWX/train.csv\")\n",
    "test = pd.read_csv(\"../Datasets/Identify the Apparels - AnalyticsVidhya/test_ScVgIM0/test.csv\")\n",
    "\n",
    "sample_submission = pd.read_csv(\"../Datasets/Identify the Apparels - AnalyticsVidhya/sample_submission_I5njJSF.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9669e050d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print an image\n",
    "img_name = rng.choice(train['id'])\n",
    "\n",
    "filepath = '../Datasets/Identify the Apparels - AnalyticsVidhya/train_LbELtWX/train/' + str(img_name) + '.png'\n",
    "\n",
    "img = imread(filepath, as_gray = True)\n",
    "img = img.astype('float32')\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training images\n",
    "train_img = []\n",
    "\n",
    "for img_name in train['id']:\n",
    "    img_path = '../Datasets/Identify the Apparels - AnalyticsVidhya/train_LbELtWX/train/' + str(img_name) + '.png'\n",
    "    \n",
    "    img = imread(img_path, as_gray = True)\n",
    "    img = img.astype('float32')\n",
    "    \n",
    "    train_img.append(img)\n",
    "    \n",
    "train_x = np.array(train_img)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening 2-dimensional images into a single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_x / train_x.max()\n",
    "train_x = train_x.reshape(-1, 28 * 28).astype('float32')\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating target for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((54000, 784), (54000,)), ((6000, 784), (6000,)))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.1, stratify = train_y)\n",
    "\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "\n",
    "# number of neurons in each layer\n",
    "input_num_units = 28*28\n",
    "hidden_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "# set remaining variables\n",
    "epochs = 20\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential(Linear(input_num_units, hidden_num_units),\n",
    "                   ReLU(),\n",
    "                   Linear(hidden_num_units, output_num_units)\n",
    "                  )\n",
    "\n",
    "# Loss function\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Define optimization aloorithm\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tensor(2.1757)\n",
      "4 tensor(1.9794)\n",
      "6 tensor(1.8084)\n",
      "8 tensor(1.6369)\n",
      "10 tensor(1.4778)\n",
      "12 tensor(1.3424)\n",
      "14 tensor(1.2272)\n",
      "16 tensor(1.1249)\n",
      "18 tensor(1.0404)\n",
      "20 tensor(0.9910)\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    x, y = Variable(torch.from_numpy(train_x)), Variable(torch.from_numpy(train_y), requires_grad = False)\n",
    "    x_val, y_val = Variable(torch.from_numpy(val_x)), Variable(torch.from_numpy(val_y), requires_grad = False)\n",
    "    \n",
    "    pred = model(x)\n",
    "    pred_val = model(x_val)\n",
    "    \n",
    "    # get loss\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss_val = loss_fn(pred_val, y_val)\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    val_losses.append(loss_val)\n",
    "    \n",
    "    # perform backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    avg_cost = avg_cost + loss.data\n",
    "    \n",
    "    if(epoch%2 != 0):\n",
    "        print(epoch+1, avg_cost)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6514629629629629\n"
     ]
    }
   ],
   "source": [
    "x, y = Variable(torch.from_numpy(train_x)), Variable(torch.from_numpy(train_y), requires_grad = False)\n",
    "pred = model(x)\n",
    "\n",
    "final_pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "\n",
    "acc_train = accuracy_score(train_y, final_pred)\n",
    "\n",
    "print(acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6475\n"
     ]
    }
   ],
   "source": [
    "x, y = Variable(torch.from_numpy(val_x)), Variable(torch.from_numpy(val_y), requires_grad = False)\n",
    "pred = model(x)\n",
    "\n",
    "final_pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "\n",
    "acc_val = accuracy_score(val_y, final_pred)\n",
    "\n",
    "print(acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to increase the number of hidden layers or play with other model parameters like the optimizer function, the number of hidden units, etc. and try to improve the performance further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test images\n",
    "\n",
    "test_img = []\n",
    "\n",
    "for img_name in test['id']:\n",
    "    img_path = '../Datasets/Identify the Apparels - AnalyticsVidhya/test_ScVgIM0/test/' + str(img_name) + '.png'\n",
    "    \n",
    "    img = imread(img_path, as_gray=True)\n",
    "    img = img.astype('float32')\n",
    "    \n",
    "    test_img.append(img)\n",
    "    \n",
    "test_x = np.array(test_img)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the images to 1-D\n",
    "test_x = test_x / train_x.max()\n",
    "\n",
    "test_x = test_x.reshape(-1, 28 * 28).astype('float32')\n",
    "\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the prediction for test images\n",
    "pred = np.argmax(model(torch.from_numpy(test_x)).data.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  60001      0\n",
       "1  60002      0\n",
       "2  60003      0\n",
       "3  60004      0\n",
       "4  60005      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace these labels with the predictions that we got from the model for test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  60001      9\n",
       "1  60002      2\n",
       "2  60003      1\n",
       "3  60004      1\n",
       "4  60005      4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing the label with prediction\n",
    "sample_submission['label'] = pred\n",
    "\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the file\n",
    "sample_submission.to_csv('../Datasets/Identify the Apparels - AnalyticsVidhya/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
